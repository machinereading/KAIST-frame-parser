{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertModel\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
    "from tqdm import tqdm, trange\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "from KAIST_frame_parser.src import dataio\n",
    "from KAIST_frame_parser.src.fn_modeling import BertForFrameIdentification\n",
    "from KAIST_frame_parser.koreanframenet import koreanframenet\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frameid():\n",
    "    def __init__(self, language='ko', version=1.1):\n",
    "        self.language = language\n",
    "        self.version = version\n",
    "        if self.language == 'en':\n",
    "            self.framenet = 'fn'+str(version)\n",
    "        elif self.language == 'ko':\n",
    "            self.framenet = 'kfn'+str(version)            \n",
    "        print('### SETINGS')\n",
    "        print('\\t# FrameNet:', self.framenet)        \n",
    "        if self.language == 'ko':\n",
    "            kfn = koreanframenet.interface(version=version)\n",
    "            self.trn, self.dev, self.tst = kfn.load_data()            \n",
    "        try:\n",
    "            target_dir = os.path.dirname(os.path.abspath( __file__ ))\n",
    "        except:\n",
    "            target_dir = '.'\n",
    "        data_path = target_dir+'/../koreanframenet/resource/info/'\n",
    "        with open(data_path+self.framenet+'_lu2idx.json','r') as f:\n",
    "            self.lu2idx = json.load(f)\n",
    "        with open(data_path+'fn1.7_frame2idx.json','r') as f:\n",
    "            self.frame2idx = json.load(f)      \n",
    "        with open(data_path+self.framenet+'_lufrmap.json','r') as f:\n",
    "            self.lufrmap = json.load(f)\n",
    "        self.idx2frame = dict(zip(self.frame2idx.values(),self.frame2idx.keys()))\n",
    "        self.idx2lu = dict(zip(self.lu2idx.values(),self.lu2idx.keys()))\n",
    "        \n",
    "    def flat_accuracy(self, preds, labels):\n",
    "        pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "        \n",
    "    def gen_bert_input_representation(self, fn_data, MAX_LEN=256, batch_size=8):\n",
    "        bert_io = dataio.for_BERT(mode='training', version=self.version)\n",
    "        data = bert_io.convert_to_bert_input_frameid(fn_data)\n",
    "        sampler = RandomSampler(fn_data)\n",
    "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)        \n",
    "        return data, sampler, dataloader\n",
    "    \n",
    "    def train(self, model_dir='.', trn=False, dev=False, MAX_LEN = 256, batch_size = 8, epoch=4):\n",
    "        model_path = model_dir+'/'+self.framenet+'-frameid.pt'\n",
    "        print('your model would be saved at', model_path)\n",
    "        # load BERT model for frameid\n",
    "        model = BertForFrameIdentification.from_pretrained(\"bert-base-multilingual-cased\", num_labels = len(self.frame2idx), num_lus = len(self.lu2idx), ludim = 64, lufrmap=self.lufrmap)\n",
    "        model.cuda();\n",
    "            \n",
    "        # gen BERT input representations            \n",
    "        trn_data, trn_sampler, trn_dataloader = frameid.gen_bert_input_representation(self, trn, MAX_LEN=256, batch_size=8)\n",
    "        #dev_data, dev_sampler, dev_data_loader = frameid.gen_bert_input_representation(dev)\n",
    "            \n",
    "        # load optimizer\n",
    "        FULL_FINETUNING = True\n",
    "        if FULL_FINETUNING:\n",
    "            param_optimizer = list(model.named_parameters())\n",
    "            no_decay = ['bias', 'gamma', 'beta']\n",
    "            optimizer_grouped_parameters = [\n",
    "                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                 'weight_decay_rate': 0.01},\n",
    "                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                 'weight_decay_rate': 0.0}\n",
    "            ]\n",
    "        else:\n",
    "            param_optimizer = list(model.classifier.named_parameters()) \n",
    "            optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "        optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "        \n",
    "        # train \n",
    "        epochs = epoch\n",
    "        max_grad_norm = 1.0\n",
    "        num_of_epoch = 0\n",
    "        accuracy_result = []\n",
    "        for _ in trange(epochs, desc=\"Epoch\"):\n",
    "            # TRAIN loop\n",
    "            model.train()\n",
    "            tr_loss = 0\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "            for step, batch in enumerate(trn_dataloader):\n",
    "                # add batch to gpu\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_tgt_idxs, b_input_lus, b_input_frames, b_input_masks = batch            \n",
    "                # forward pass\n",
    "                loss = model(b_input_ids, token_type_ids=None, tgt_idxs=b_input_tgt_idxs, \n",
    "                             lus=b_input_lus, frames=b_input_frames, attention_mask=b_input_masks)\n",
    "                # backward pass\n",
    "                loss.backward()\n",
    "                # track train loss\n",
    "                tr_loss += loss.item()\n",
    "                nb_tr_examples += b_input_ids.size(0)\n",
    "                nb_tr_steps += 1\n",
    "                # gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "                # update parameters\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "            # print train loss per epoch\n",
    "            print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "            torch.save(model, model_path)\n",
    "            num_of_epoch += 1\n",
    "        print('...training is done')\n",
    "        \n",
    "    def test(self, tst=False, model_dir='.', MAX_LEN = 256, batch_size = 8):\n",
    "        model_path = model_dir+'/'+self.framenet+'-frameid.pt'\n",
    "        print('your model is', model_path)\n",
    "        model = torch.load(model_path)\n",
    "        \n",
    "        model.eval()\n",
    "        tst_data, tst_sampler, tst_dataloader = frameid.gen_bert_input_representation(self, tst, MAX_LEN=256, batch_size=8)\n",
    "        \n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "        predictions , true_labels, scores, candis, all_lus = [], [], [], [], []\n",
    "        for batch in tst_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_tgt_idxs, b_lus, b_frames, b_masks = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                tmp_eval_loss = model(b_input_ids, token_type_ids=None, tgt_idxs=b_tgt_idxs, \n",
    "                                     lus=b_lus, frames=b_frames, attention_mask=b_masks)\n",
    "                logits = model(b_input_ids, token_type_ids=None, tgt_idxs=b_tgt_idxs, \n",
    "                                lus=b_lus, attention_mask=b_masks)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_frames.to('cpu').numpy()          \n",
    "            masks = dataio.get_masks(b_lus, self.lufrmap, num_label=len(self.frame2idx)).to(device)\n",
    "            for lu in b_lus:\n",
    "                candi_idx = self.lufrmap[str(int(lu))]\n",
    "                candi = [self.idx2frame[c] for c in candi_idx]\n",
    "                candi_txt = ','.join(candi)\n",
    "                candi_txt = str(len(candi))+'\\t'+candi_txt\n",
    "                candis.append(candi_txt)\n",
    "                all_lus.append(self.idx2lu[int(lu)])\n",
    "            \n",
    "            for b_idx in range(len(logits)):\n",
    "                logit = logits[b_idx]\n",
    "                mask = masks[b_idx]\n",
    "                b_pred_idxs, b_pred_logits = [],[]\n",
    "                for fr_idx in range(len(mask)):\n",
    "                    if mask[fr_idx] > 0:\n",
    "                        b_pred_idxs.append(fr_idx)\n",
    "                        b_pred_logits.append(logit[0][fr_idx].item())\n",
    "                b_pred_idxs = torch.tensor(b_pred_idxs)\n",
    "                b_pred_logits = torch.tensor(b_pred_logits)\n",
    "                sm = nn.Softmax()\n",
    "                b_pred_logits = sm(b_pred_logits).view(1, -1)\n",
    "                score, indice = b_pred_logits.max(1)                \n",
    "                prediction = b_pred_idxs[indice]\n",
    "                predictions.append([int(prediction)])\n",
    "                score = float(score)\n",
    "                scores.append(score)\n",
    "            true_labels.append(label_ids)\n",
    "            tmp_eval_accuracy = frameid.flat_accuracy(self, logits, label_ids)\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "            nb_eval_examples += b_input_ids.size(0)\n",
    "            nb_eval_steps += 1\n",
    "        pred_tags = [self.idx2frame[p_i] for p in predictions for p_i in p]\n",
    "        valid_tags = [self.idx2frame[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "        acc = accuracy_score(pred_tags, valid_tags)\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
    "        \n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluation for each epoch\n",
    "#         model.eval()\n",
    "#         eval_loss, eval_accuracy = 0, 0\n",
    "#         nb_eval_steps, nb_eval_examples = 0, 0\n",
    "#         predictions , true_labels, scores, candis, all_lus = [], [], [], [], []\n",
    "#         for batch in tst_dataloader:\n",
    "#             batch = tuple(t.to(device) for t in batch)\n",
    "#             b_input_ids, b_tgt_idxs, b_lus, b_senses, b_masks = batch\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 tmp_eval_loss = model(b_input_ids, token_type_ids=None, tgt_idxs=b_tgt_idxs, \n",
    "#                                      lus=b_lus, senses=b_senses, attention_mask=b_masks)\n",
    "#                 logits = model(b_input_ids, token_type_ids=None, tgt_idxs=b_tgt_idxs, \n",
    "#                                 lus=b_lus, attention_mask=b_masks)\n",
    "#             logits = logits.detach().cpu().numpy()\n",
    "#             label_ids = b_senses.to('cpu').numpy()          \n",
    "#             masks = dataio.get_masks(b_lus, lusensemap, num_label=len(sense2idx)).to(device)\n",
    "#             for lu in b_lus:\n",
    "#                 candi_idx = lusensemap[str(int(lu))]\n",
    "#                 candi = [idx2sense[c] for c in candi_idx]\n",
    "#                 candi_txt = ','.join(candi)\n",
    "#                 candi_txt = str(len(candi))+'\\t'+candi_txt\n",
    "#                 candis.append(candi_txt)\n",
    "#                 all_lus.append(idx2lu[int(lu)])\n",
    "            \n",
    "#             for b_idx in range(len(logits)):\n",
    "#                 logit = logits[b_idx]\n",
    "#                 mask = masks[b_idx]\n",
    "#                 b_pred_idxs, b_pred_logits = [],[]\n",
    "#                 for fr_idx in range(len(mask)):\n",
    "#                     if mask[fr_idx] > 0:\n",
    "#                         b_pred_idxs.append(fr_idx)\n",
    "#                         b_pred_logits.append(logit[0][fr_idx].item())\n",
    "#                 b_pred_idxs = torch.tensor(b_pred_idxs)\n",
    "#                 b_pred_logits = torch.tensor(b_pred_logits)\n",
    "#                 sm = nn.Softmax()\n",
    "#                 b_pred_logits = sm(b_pred_logits).view(1, -1)\n",
    "#                 score, indice = b_pred_logits.max(1)                \n",
    "#                 prediction = b_pred_idxs[indice]\n",
    "#                 predictions.append([int(prediction)])\n",
    "#                 score = float(score)\n",
    "#                 scores.append(score)\n",
    "#             true_labels.append(label_ids)\n",
    "#             tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "#             eval_loss += tmp_eval_loss.mean().item()\n",
    "#             eval_accuracy += tmp_eval_accuracy\n",
    "#             nb_eval_examples += b_input_ids.size(0)\n",
    "#             nb_eval_steps += 1\n",
    "            \n",
    "#         eval_loss = eval_loss/nb_eval_steps\n",
    "#         print(\"Validation loss: {}\".format(eval_loss))\n",
    "#         print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "#         pred_tags = [idx2sense[p_i] for p in predictions for p_i in p]\n",
    "#         valid_tags = [idx2sense[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "#         acc = accuracy_score(pred_tags, valid_tags)\n",
    "#         accuracy_result.append(acc)\n",
    "#         print(\"Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
    "        \n",
    "#         result_path = result_dir+str(version)+'.frameid-'+str(num_of_epoch)+'.tsv'\n",
    "#         with open(result_path,'w') as f:\n",
    "#             line = 'gold' + '\\t' + 'prediction' + '\\t' + 'score' + '\\t' + 'input_lu' + '\\t' + 'sense_candidates'\n",
    "#             f.write(line+'\\n')\n",
    "#             for item in range(len(pred_tags)):\n",
    "#                 line = valid_tags[item] + '\\t' + pred_tags[item] + '\\t' + str(scores[item]) +'\\t'+ all_lus[item]+'\\t' + candis[item]\n",
    "#                 f.write(line+'\\n')\n",
    "#     accuracy_result_path = result_dir+str(version)+'.frameid.accuracy'\n",
    "#     with open(accuracy_result_path,'w') as f:\n",
    "#         n = 0\n",
    "#         for acc in accuracy_result:\n",
    "#             f.write('epoch:'+str(n)+'\\t' + 'accuracy: '+str(acc)+'\\n')\n",
    "#             n +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
