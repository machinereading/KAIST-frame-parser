{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src import dataio, etri\n",
    "import targetid\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "from koreanframenet.src import conll2textae\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SETTINGS\n",
      "\t# FrameNet: kfn1.1\n",
      "\t# PARSER: srl-based\n",
      "\t# MODEL_PATH: /disk_4/resource/models/kfn/\n",
      "\t# (your frameid model should be: /disk_4/resource/models/kfn/frameid-1.1.pt\n",
      "\t# (your argid model should be: /disk_4/resource/models/kfn/arg_classifier-1.1.pt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_dir = os.path.dirname( os.path.abspath( __file__ ))\n",
    "except:\n",
    "    config_dir = '.'\n",
    "    \n",
    "config_file = config_dir+'/config.json'\n",
    "\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "framenet = config['framenet']\n",
    "version = float(framenet.split('fn')[-1])\n",
    "model_dir = config['model_dir']\n",
    "frameid_model_path = model_dir+'frameid-'+str(version)+'.pt'\n",
    "arg_classifier_model_path = model_dir+'arg_classifier-'+str(version)+'.pt'\n",
    "\n",
    "print('### SETTINGS')\n",
    "print('\\t# FrameNet:', framenet)\n",
    "print('\\t# PARSER:', config['parser'])\n",
    "print('\\t# MODEL_PATH:', model_dir)\n",
    "print('\\t# (your frameid model should be:', frameid_model_path)\n",
    "print('\\t# (your argid model should be:', arg_classifier_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './koreanframenet/resource/info/'\n",
    "\n",
    "with open(data_path+framenet+'_lu2idx.json','r') as f:\n",
    "    lu2idx = json.load(f)\n",
    "with open(data_path+'fn1.7_frame2idx.json','r') as f:\n",
    "    frame2idx = json.load(f)\n",
    "with open(data_path+'fn1.7_fe2idx.json','r') as f:\n",
    "    arg2idx = json.load(f)\n",
    "with open(data_path+framenet+'_lufrmap.json','r') as f:\n",
    "    lufrmap = json.load(f)\n",
    "    \n",
    "idx2frame = dict(zip(frame2idx.values(),frame2idx.keys()))\n",
    "idx2lu = dict(zip(lu2idx.values(),lu2idx.keys()))\n",
    "idx2arg = dict(zip(arg2idx.values(),arg2idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class models():\n",
    "    def __init__(self, mode='parser', version=1.1):\n",
    "        self.version = version\n",
    "        self.mode = mode\n",
    "        self.bert_io = dataio.for_BERT(mode=self.mode, version=self.version)\n",
    "        self.frameid_model = torch.load(frameid_model_path)\n",
    "        self.arg_classifier_model = torch.load(arg_classifier_model_path)\n",
    "        \n",
    "    def frame_identifier(self, tgt_data):\n",
    "        bert_inputs = self.bert_io.convert_to_bert_input_frameid(tgt_data)\n",
    "        dataloader = DataLoader(bert_inputs, sampler=None, batch_size=1)\n",
    "        \n",
    "        predictions, scores, candis = [], [], []\n",
    "        for batch in dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_tgt_idxs, b_lus, b_masks = batch\n",
    "            with torch.no_grad():\n",
    "                logits = self.frameid_model(b_input_ids, token_type_ids=None, tgt_idxs=b_tgt_idxs, \n",
    "                                lus=b_lus, attention_mask=b_masks)\n",
    "            logits = logits.detach().cpu().numpy()                \n",
    "            masks = self.bert_io.get_masks(b_lus, model='frameid').to(device)\n",
    "            \n",
    "            for lu in b_lus:\n",
    "                candi_idx = lufrmap[str(int(lu))]\n",
    "                candi = [idx2frame[c] for c in candi_idx]\n",
    "                candi_txt = ','.join(candi)\n",
    "                candi_txt = str(len(candi))+'\\t'+candi_txt\n",
    "                candis.append(candi_txt)\n",
    "            for b_idx in range(len(logits)):\n",
    "                logit = logits[b_idx]\n",
    "                mask = masks[b_idx]\n",
    "                b_pred_idxs, b_pred_logits = [],[]\n",
    "                for fr_idx in range(len(mask)):\n",
    "                    if mask[fr_idx] > 0:\n",
    "                        b_pred_idxs.append(fr_idx)\n",
    "                        b_pred_logits.append(logit[0][fr_idx].item())\n",
    "                b_pred_idxs = torch.tensor(b_pred_idxs)\n",
    "                b_pred_logits = torch.tensor(b_pred_logits)\n",
    "                sm = nn.Softmax()\n",
    "                b_pred_logits = sm(b_pred_logits).view(1, -1)\n",
    "                score, indice = b_pred_logits.max(1)                \n",
    "                prediction = b_pred_idxs[indice]\n",
    "                predictions.append([int(prediction)])\n",
    "                score = float(score)\n",
    "                scores.append(score)\n",
    "        pred_tags = self.bert_io.idx2tag(predictions, model='frameid')       \n",
    "        conll, tuples = [],[]\n",
    "        for i in range(len(tgt_data)):\n",
    "            instance = tgt_data[i]\n",
    "            tokens, targets = instance[0], instance[1]\n",
    "            frames = ['_' for i in range(len(targets))]\n",
    "            for t in range(len(targets)):\n",
    "                if targets[t] != '_':\n",
    "                    frames[t] = pred_tags[i]\n",
    "            instance.append(frames)\n",
    "            conll.append(instance)\n",
    "            \n",
    "            tup = (pred_tags[i], scores[i])\n",
    "            tuples.append(tup)\n",
    "            \n",
    "        return conll, tuples\n",
    "    \n",
    "    def arg_classifier(self, fr_data, arg_tokens):\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        text = ' '.join(fr_data[0][0])\n",
    "        orig_tokens, bert_tokens, orig_to_tok_map = bert_io.bert_tokenizer_assign_to_last_token(text)     \n",
    "                \n",
    "        bert_inputs = self.bert_io.convert_to_bert_input_arg_classifier(fr_data)\n",
    "        dataloader = DataLoader(bert_inputs, sampler=None, batch_size=1)\n",
    "        predictions, scores = [],[]\n",
    "        for batch in dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_tgt_idxs, b_lus, b_frames, b_masks = batch\n",
    "            \n",
    "            arg_word_idx = arg_tokens[-1]\n",
    "            arg_idx = [[orig_to_tok_map[arg_word_idx]]]\n",
    "            b_arg_idxs = torch.tensor(arg_idx)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = self.arg_classifier_model(b_input_ids, token_type_ids=None, tgt_idxs=b_tgt_idxs, \n",
    "                         lus=b_lus, frames=b_frames, arg_idxs=b_arg_idxs, attention_mask=b_masks)\n",
    "            logits = logits.detach().cpu().numpy()      \n",
    "            masks = self.bert_io.get_masks(b_frames, model='argid').to(device)\n",
    "            \n",
    "            for b_idx in range(len(logits)):\n",
    "                logit = logits[b_idx]\n",
    "                mask = masks[b_idx]\n",
    "                b_pred_idxs, b_pred_logits = [],[]\n",
    "                for fe_idx in range(len(mask)):\n",
    "                    if mask[fe_idx] > 0:\n",
    "                        b_pred_idxs.append(fe_idx)\n",
    "                        b_pred_logits.append(logit[0][fe_idx].item())\n",
    "                b_pred_idxs = torch.tensor(b_pred_idxs)\n",
    "                b_pred_logits = torch.tensor(b_pred_logits)\n",
    "                sm = nn.Softmax()\n",
    "                b_pred_logits = sm(b_pred_logits).view(1, -1)\n",
    "                score, indice = b_pred_logits.max(1)                \n",
    "                prediction = b_pred_idxs[indice]\n",
    "                predictions.append([int(prediction)])\n",
    "                score = float(score)\n",
    "                scores.append(score)\n",
    "            pred_tags = self.bert_io.idx2tag(predictions, model='argid')\n",
    "            result.append(pred_tags)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_models = models(mode='parser', version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()\n",
    "def doc2sents(text):\n",
    "    result = []\n",
    "    n = 0\n",
    "    sents = text.split('. ')\n",
    "    for sent in sents:\n",
    "        if len(sent) >0:\n",
    "            sent = sent+'.'\n",
    "            stringuri = 'test_0_'+str(n)\n",
    "            tup = (sent, stringuri)\n",
    "            result.append(tup)\n",
    "            n +=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result2triples(text, conll, tuples, stringuri):\n",
    "    triples = []\n",
    "    triple = (str(stringuri), 'nif:isString', text)\n",
    "    triples.append(triple)\n",
    "    # for target_id\n",
    "    if len(conll) > 0:\n",
    "        for i in range(len(conll)):\n",
    "            instance = conll[i]\n",
    "            tokens, targets, frames, args = instance[0], instance[1], instance[2], instance[3]\n",
    "            for tok in range(len(tokens)):\n",
    "                if frames[tok] != '_':\n",
    "                    frame = 'frame:'+frames[tok]\n",
    "                    lu = targets[tok]\n",
    "            triple = (frame, 'frdf:provinence', str(stringuri))\n",
    "            triples.append(triple)\n",
    "            triple = (frame, 'frdf:lu', lu)\n",
    "            triples.append(triple)\n",
    "            triple = (frame, 'frdf:score', str(tuples[i][1]))\n",
    "            triples.append(triple)\n",
    "            \n",
    "            #args to triples\n",
    "            for idx in range(len(args)):\n",
    "                arg_tag = args[idx]\n",
    "                arg_tokens = []\n",
    "                if arg_tag.startswith('B'):\n",
    "                    fe_tag = arg_tag.split('-')[1]\n",
    "                    arg_tokens.append(tokens[idx])\n",
    "                    next_idx = idx + 1\n",
    "                    while next_idx < len(args) and args[next_idx] == 'I-'+fe_tag:\n",
    "                        arg_tokens.append(tokens[next_idx])\n",
    "                        next_idx +=1\n",
    "                            \n",
    "                    arg_text = ' '.join(arg_tokens)\n",
    "                    triple = (frame, 'arg:'+fe_tag, arg_text)\n",
    "                    triples.append(triple)\n",
    "                        \n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2pa(text):\n",
    "    nlp = etri.getETRI(text)    \n",
    "    conll_2009 = etri.getETRI_CoNLL2009(nlp)\n",
    "    predicate_argument = etri.phrase_parser(conll_2009, nlp)\n",
    "    return predicate_argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_identifier(conll):\n",
    "    text = ' '.join(conll[0][0])\n",
    "    pas = sent2pa(text)\n",
    "    \n",
    "    result = []\n",
    "    for anno in conll:\n",
    "        args = ['O' for i in range(len(anno[1]))]\n",
    "        for idx in range(len(anno[1])):\n",
    "            if anno[1][idx] != '_':\n",
    "                lu = anno[1][idx]\n",
    "                frame = anno[2][idx]\n",
    "                target_idx = idx\n",
    "        for pa in pas:\n",
    "            if target_idx == pa['predicate']['id']:                \n",
    "                for argument in pa['arguments']:\n",
    "                    arg_tokens = argument['tokens']\n",
    "                    \n",
    "                    pred = fn_models.arg_classifier([anno], arg_tokens)[0][0]\n",
    "                    for arg_token_idx in range(len(arg_tokens)):\n",
    "                        arg_token = arg_tokens[arg_token_idx]\n",
    "                        if arg_token_idx == 0:\n",
    "                            fe = 'B-'+pred\n",
    "                        else:\n",
    "                            fe = 'I-'+pred\n",
    "                        args[arg_token] = fe                \n",
    "                    \n",
    "        new_anno = anno\n",
    "        new_anno.append(args)\n",
    "        result.append(new_anno)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data, sentence_id):\n",
    "    input_data = dataio.preprocessor(data)\n",
    "    text = data\n",
    "    \n",
    "    tgt_data = targetid.baseline(input_data)\n",
    "    fid_data, fid_result  = fn_models.frame_identifier(tgt_data)\n",
    "    argid_data = arg_identifier(fid_data)   \n",
    "    \n",
    "    framegraph = result2triples(text, argid_data, fid_result, sentence_id)\n",
    "    textae = conll2textae.get_textae(argid_data)\n",
    "        \n",
    "    result = {}\n",
    "    result['graph'] = framegraph\n",
    "    result['textae'] = textae\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('test:offset_0_53',\n",
      "  'nif:isString',\n",
      "  '헤밍웨이는 1899년 7월 21일 미국 일리노이에서 태어났고, 62세에 자살로 사망했다.'),\n",
      " ('frame:Origin', 'frdf:provinence', 'test:offset_0_53'),\n",
      " ('frame:Origin', 'frdf:lu', '미국.n'),\n",
      " ('frame:Origin', 'frdf:score', '1.0'),\n",
      " ('frame:Being_born', 'frdf:provinence', 'test:offset_0_53'),\n",
      " ('frame:Being_born', 'frdf:lu', '태어나다.v'),\n",
      " ('frame:Being_born', 'frdf:score', '1.0'),\n",
      " ('frame:Being_born', 'arg:Child', '헤밍웨이는'),\n",
      " ('frame:Being_born', 'arg:Time', '1899년 7월 21일'),\n",
      " ('frame:Being_born', 'arg:Place', '미국 일리노이에서'),\n",
      " ('frame:Killing', 'frdf:provinence', 'test:offset_0_53'),\n",
      " ('frame:Killing', 'frdf:lu', '자살.n'),\n",
      " ('frame:Killing', 'frdf:score', '1.0'),\n",
      " ('frame:Death', 'frdf:provinence', 'test:offset_0_53'),\n",
      " ('frame:Death', 'frdf:lu', '사망.n'),\n",
      " ('frame:Death', 'frdf:score', '1.0'),\n",
      " ('frame:Death', 'arg:Protagonist', '헤밍웨이는'),\n",
      " ('frame:Death', 'arg:Time', '62세에'),\n",
      " ('frame:Death', 'arg:Containing_event', '자살로')]\n"
     ]
    }
   ],
   "source": [
    "# text = '헤밍웨이는 1899년 7월 21일 미국 일리노이에서 태어났고, 62세에 자살로 사망했다.'\n",
    "# stringuri = 'test:offset_0_53'\n",
    "# parsed = main(text, stringuri)\n",
    "# pprint(parsed['graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = '미중 무역전쟁을 벌이는 중국이 이번에는 브라질산 설탕 수입을 제한하면서 브라질과 갈등을 빚고 있다.'\n",
    "# text = '바둑 인공지능(AI) 알파고에 도전장을 던진 중국랭킹 1위 커제 9단이 초반부터 극단적인 실리작전을 들고 나왔다.'\n",
    "# text = '마이크로소프트의 공동 창업자로 억만장자 반열에 오른 빌 게이츠가 20대 젊은이들에게 추천하는 유망 분야로 인공지능(AI)과 에너지, 생명공학을 꼽았다.'\n",
    "# text = '반면 안철수 바른미래당 대표가 만든 안랩(053800)은 전날 대비 0.88% 하락한 7만8400원에 거래 중이다.'\n",
    "# text = '헤밍웨이는 1899년 7월 21일 일리노이주에서 태어났고, 62세에 자살로 사망했다.'\n",
    "# text = '태풍 Hugo가 남긴 피해들과 회사 내 몇몇 주요 부서들의 저조한 실적들을 반영하여 Aetna Life and Caualty Co.의 3분기 순이익이 182.6 백만 달러 또는 주당 1.63 달러로 22 % 하락하였다.'\n",
    "# stringuri = 'test:offset_0_53'\n",
    "# parsed = main(text, stringuri)\n",
    "# pprint(parsed['graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = '어니스트 헤밍웨이는 미국의 소설가이자 저널리스트이다. 1854년 노벨 문학상을 수상하였다. 헤밍웨이는 1899년 7월 21일 일리노이주에서 태어났다. 헤밍웨이는 풀린 파이퍼와 이혼한 뒤 마사 겔혼과 재혼하였다. 헤밍웨이는 1961년 아이다호 주에서 62세의 나이에 자살했다.'\n",
    "# sents = doc2sents(text)\n",
    "# framegraphs = []\n",
    "# for text, stringuri in sents:\n",
    "#     parsed = main(text, stringuri)\n",
    "#     pprint(parsed['graph'])\n",
    "#     print('')\n",
    "# #     framegraphs+=(parsed['framegraph'])\n",
    "# pprint(framegraphs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
