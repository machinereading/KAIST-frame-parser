{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "### Korean FrameNet ###\n",
      "\t# contact: hahmyg@kaist, hahmyg@gmail.com #\n",
      "\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['이혼하']\n",
      "['뒤']\n",
      "['마사']\n",
      "[]\n",
      "['재혼하']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from src import dataio\n",
    "import targetid\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname( os.path.abspath( __file__ ))\n",
    "except:\n",
    "    dir_path = './'\n",
    "frameid_model_path = dir_path+'models/kfn/frameid-1.0.pt'\n",
    "version = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './koreanframenet/resource/info/kfn'+str(version)+'_'\n",
    "\n",
    "with open(data_path+'lu2idx.json','r') as f:\n",
    "    lu2idx = json.load(f)\n",
    "with open('./koreanframenet/resource/info/fn1.7_frame2idx.json','r') as f:\n",
    "    sense2idx = json.load(f)      \n",
    "with open(data_path+'lufrmap.json','r') as f:\n",
    "    lusensemap = json.load(f)\n",
    "    \n",
    "idx2sense = dict(zip(sense2idx.values(),sense2idx.keys()))\n",
    "idx2lu = dict(zip(lu2idx.values(),lu2idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class models():\n",
    "    def __init__(self, mode='parser', version=1.0):\n",
    "        self.version = version\n",
    "        self.mode = mode\n",
    "        self.bert_io = dataio.for_BERT(mode=self.mode, version=self.version)\n",
    "        self.frameid_model = torch.load(frameid_model_path)\n",
    "        \n",
    "    def frame_identifier(self, tgt_data):\n",
    "        bert_inputs = self.bert_io.convert_to_bert_input_frameid(tgt_data)\n",
    "        dataloader = DataLoader(bert_inputs, sampler=None, batch_size=1)\n",
    "        \n",
    "        predictions, scores, candis = [], [], []\n",
    "        for batch in dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_tgt_idxs, b_lus, b_masks = batch\n",
    "            with torch.no_grad():\n",
    "                logits = self.frameid_model(b_input_ids, token_type_ids=None, tgt_idxs=b_tgt_idxs, \n",
    "                                lus=b_lus, attention_mask=b_masks)\n",
    "            logits = logits.detach().cpu().numpy()      \n",
    "            masks = self.bert_io.get_masks(b_lus, model='frameid').to(device)\n",
    "            \n",
    "            for lu in b_lus:\n",
    "                candi_idx = lusensemap[str(int(lu))]\n",
    "                candi = [idx2sense[c] for c in candi_idx]\n",
    "                candi_txt = ','.join(candi)\n",
    "                candi_txt = str(len(candi))+'\\t'+candi_txt\n",
    "                candis.append(candi_txt)\n",
    "            for b_idx in range(len(logits)):\n",
    "                logit = logits[b_idx]\n",
    "                mask = masks[b_idx]\n",
    "                b_pred_idxs, b_pred_logits = [],[]\n",
    "                for fr_idx in range(len(mask)):\n",
    "                    if mask[fr_idx] > 0:\n",
    "                        b_pred_idxs.append(fr_idx)\n",
    "                        b_pred_logits.append(logit[0][fr_idx].item())\n",
    "                b_pred_idxs = torch.tensor(b_pred_idxs)\n",
    "                b_pred_logits = torch.tensor(b_pred_logits)\n",
    "                sm = nn.Softmax()\n",
    "                b_pred_logits = sm(b_pred_logits).view(1, -1)\n",
    "                score, indice = b_pred_logits.max(1)                \n",
    "                prediction = b_pred_idxs[indice]\n",
    "                predictions.append([int(prediction)])\n",
    "                score = float(score)\n",
    "                scores.append(score)\n",
    "        pred_tags = self.bert_io.idx2tag(predictions)       \n",
    "        conll, tuples = [],[]\n",
    "        for i in range(len(tgt_data)):\n",
    "            instance = tgt_data[i]\n",
    "            tokens, targets = instance[0], instance[1]\n",
    "            frames = ['_' for i in range(len(targets))]\n",
    "            for t in range(len(targets)):\n",
    "                if targets[t] != '_':\n",
    "                    frames[t] = pred_tags[i]\n",
    "            instance.append(frames)\n",
    "            conll.append(instance)\n",
    "            \n",
    "            tup = (pred_tags[i], scores[i])\n",
    "            tuples.append(tup)\n",
    "            \n",
    "        return conll, tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './/models/kfn/frameid-1.0.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7539c0844cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfn_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'parser'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d73188e8df72>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, version)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_BERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeid_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeid_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mframe_identifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './/models/kfn/frameid-1.0.pt'"
     ]
    }
   ],
   "source": [
    "fn_models = models(mode='parser', version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()\n",
    "def doc2sents(text):\n",
    "    result = []\n",
    "    n = 0\n",
    "    sents = text.split('. ')\n",
    "    for sent in sents:\n",
    "        if len(sent) >0:\n",
    "            sent = sent+'.'\n",
    "            stringuri = 'test_0_'+str(n)\n",
    "            tup = (sent, stringuri)\n",
    "            result.append(tup)\n",
    "            n +=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result2triples(text, conll, tuples, stringuri):\n",
    "    triples = []\n",
    "    triple = (str(stringuri), 'nif:isString', text)\n",
    "    triples.append(triple)\n",
    "    # for target_id\n",
    "    if len(conll) > 0:\n",
    "        for i in range(len(conll)):\n",
    "            instance = conll[i]\n",
    "            tokens, targets, frames = instance[0], instance[1], instance[2]\n",
    "            for tok in range(len(tokens)):\n",
    "                if frames[tok] != '_':\n",
    "                    frame = 'frame:'+frames[tok]\n",
    "                    lu = targets[tok]\n",
    "            triple = (frame, 'frdf:provinence', str(stringuri))\n",
    "            triples.append(triple)\n",
    "            triple = (frame, 'frdf:lu', lu)\n",
    "            triples.append(triple)\n",
    "            triple = (frame, 'frdf:score', str(tuples[i][1]))\n",
    "            triples.append(triple)\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data, sentence_id):\n",
    "    input_data = dataio.preprocessor(data)\n",
    "    text = data\n",
    "    tgt_data = targetid.baseline(input_data)\n",
    "    fid_data, fid_result  = fn_models.frame_identifier(tgt_data)\n",
    "    \n",
    "    framegraph = result2triples(text, fid_data, fid_result, sentence_id)\n",
    "    return framegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '애플은 스티브 잡스와 스티브 워즈니악과 론 웨인이 1976년에 설립한 회사이다.'\n",
    "stringuri = 'test:offset_0_53'\n",
    "framegraph = main(text, stringuri)\n",
    "pprint(framegraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '어니스트 헤밍웨이는 미국의 소설가이자 저널리스트이다. 1854년 노벨 문학상을 수상하였다. 헤밍웨이는 1899년 7월 21일 일리노이주에서 태어났다. 헤밍웨이는 풀린 파이퍼와 이혼한 뒤 마사 겔혼과 재혼하였다. 1961년 아이다호 주에서 62세의 나이에 자살했다.'\n",
    "sents = doc2sents(text)\n",
    "framegraphs = []\n",
    "for text, stringuri in sents:\n",
    "    framegraph = main(text, stringuri)\n",
    "    framegraphs+=(framegraph)\n",
    "pprint(framegraphs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
