{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "### Korean FrameNet ###\n",
      "\t# contact: hahmyg@kaist, hahmyg@gmail.com #\n",
      "\n",
      "pos: [('헤밍웨이', 'UN'), ('는', 'JX')]\n",
      "targets: []\n",
      "pos: [('미국', 'NNP'), ('에서', 'JKM')]\n",
      "targets: ['미국']\n",
      "pos: [('태어나', 'VV'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')]\n",
      "targets: ['태어나']\n",
      "result\n",
      "[[['헤밍웨이는', '미국에서', '태어났다.'], ['_', '미국.n', '_']], [['헤밍웨이는', '미국에서', '태어났다.'], ['_', '_', '태어나다.v']]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from src import dataio, etri\n",
    "import targetid\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "from koreanframenet.src import conll2textae\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dir_path = os.path.dirname( os.path.abspath( __file__ ))\n",
    "except:\n",
    "#     dir_path = '.'\n",
    "    dir_path = '/disk_4/resource'\n",
    "\n",
    "version = 1.1\n",
    "frameid_model_path = dir_path+'/models/kfn/frameid-'+str(version)+'.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './koreanframenet/resource/info/kfn'+str(version)+'_'\n",
    "\n",
    "with open(data_path+'lu2idx.json','r') as f:\n",
    "    lu2idx = json.load(f)\n",
    "with open('./koreanframenet/resource/info/fn1.7_frame2idx.json','r') as f:\n",
    "    sense2idx = json.load(f)      \n",
    "with open(data_path+'lufrmap.json','r') as f:\n",
    "    lusensemap = json.load(f)\n",
    "    \n",
    "idx2sense = dict(zip(sense2idx.values(),sense2idx.keys()))\n",
    "idx2lu = dict(zip(lu2idx.values(),lu2idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class models():\n",
    "    def __init__(self, mode='parser', version=1.0):\n",
    "        self.version = version\n",
    "        self.mode = mode\n",
    "        self.bert_io = dataio.for_BERT(mode=self.mode, version=self.version)\n",
    "        self.frameid_model = torch.load(frameid_model_path)\n",
    "        \n",
    "    def frame_identifier(self, tgt_data):\n",
    "        bert_inputs = self.bert_io.convert_to_bert_input_frameid(tgt_data)\n",
    "        dataloader = DataLoader(bert_inputs, sampler=None, batch_size=1)\n",
    "        \n",
    "        predictions, scores, candis = [], [], []\n",
    "        for batch in dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_tgt_idxs, b_lus, b_masks = batch\n",
    "            with torch.no_grad():\n",
    "                logits = self.frameid_model(b_input_ids, token_type_ids=None, tgt_idxs=b_tgt_idxs, \n",
    "                                lus=b_lus, attention_mask=b_masks)\n",
    "            logits = logits.detach().cpu().numpy()      \n",
    "            masks = self.bert_io.get_masks(b_lus, model='frameid').to(device)\n",
    "            \n",
    "            for lu in b_lus:\n",
    "                candi_idx = lusensemap[str(int(lu))]\n",
    "                candi = [idx2sense[c] for c in candi_idx]\n",
    "                candi_txt = ','.join(candi)\n",
    "                candi_txt = str(len(candi))+'\\t'+candi_txt\n",
    "                candis.append(candi_txt)\n",
    "            for b_idx in range(len(logits)):\n",
    "                logit = logits[b_idx]\n",
    "                mask = masks[b_idx]\n",
    "                b_pred_idxs, b_pred_logits = [],[]\n",
    "                for fr_idx in range(len(mask)):\n",
    "                    if mask[fr_idx] > 0:\n",
    "                        b_pred_idxs.append(fr_idx)\n",
    "                        b_pred_logits.append(logit[0][fr_idx].item())\n",
    "                b_pred_idxs = torch.tensor(b_pred_idxs)\n",
    "                b_pred_logits = torch.tensor(b_pred_logits)\n",
    "                sm = nn.Softmax()\n",
    "                b_pred_logits = sm(b_pred_logits).view(1, -1)\n",
    "                score, indice = b_pred_logits.max(1)                \n",
    "                prediction = b_pred_idxs[indice]\n",
    "                predictions.append([int(prediction)])\n",
    "                score = float(score)\n",
    "                scores.append(score)\n",
    "        pred_tags = self.bert_io.idx2tag(predictions)       \n",
    "        conll, tuples = [],[]\n",
    "        for i in range(len(tgt_data)):\n",
    "            instance = tgt_data[i]\n",
    "            tokens, targets = instance[0], instance[1]\n",
    "            frames = ['_' for i in range(len(targets))]\n",
    "            for t in range(len(targets)):\n",
    "                if targets[t] != '_':\n",
    "                    frames[t] = pred_tags[i]\n",
    "            instance.append(frames)\n",
    "            conll.append(instance)\n",
    "            \n",
    "            tup = (pred_tags[i], scores[i])\n",
    "            tuples.append(tup)\n",
    "            \n",
    "        return conll, tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_models = models(mode='parser', version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()\n",
    "def doc2sents(text):\n",
    "    result = []\n",
    "    n = 0\n",
    "    sents = text.split('. ')\n",
    "    for sent in sents:\n",
    "        if len(sent) >0:\n",
    "            sent = sent+'.'\n",
    "            stringuri = 'test_0_'+str(n)\n",
    "            tup = (sent, stringuri)\n",
    "            result.append(tup)\n",
    "            n +=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result2triples(text, conll, tuples, stringuri):\n",
    "    triples = []\n",
    "    triple = (str(stringuri), 'nif:isString', text)\n",
    "    triples.append(triple)\n",
    "    # for target_id\n",
    "    if len(conll) > 0:\n",
    "        for i in range(len(conll)):\n",
    "            instance = conll[i]\n",
    "            tokens, targets, frames, args = instance[0], instance[1], instance[2], instance[3]\n",
    "            for tok in range(len(tokens)):\n",
    "                if frames[tok] != '_':\n",
    "                    frame = 'frame:'+frames[tok]\n",
    "                    lu = targets[tok]\n",
    "            triple = (frame, 'frdf:provinence', str(stringuri))\n",
    "            triples.append(triple)\n",
    "            triple = (frame, 'frdf:lu', lu)\n",
    "            triples.append(triple)\n",
    "            triple = (frame, 'frdf:score', str(tuples[i][1]))\n",
    "            triples.append(triple)\n",
    "            \n",
    "            #args to triples\n",
    "            for idx in range(len(args)):\n",
    "                arg_tag = args[idx]\n",
    "                arg_tokens = []\n",
    "                if arg_tag.startswith('B'):\n",
    "                    fe_tag = arg_tag.split('-')[1]\n",
    "                    arg_tokens.append(tokens[idx])\n",
    "                    next_idx = idx + 1\n",
    "                    while next_idx < len(args) and args[next_idx] == 'I-'+fe_tag:\n",
    "                        arg_tokens.append(tokens[next_idx])\n",
    "                        next_idx +=1\n",
    "                            \n",
    "                    arg_text = ' '.join(arg_tokens)\n",
    "                    triple = (frame, 'frdf:arg', arg_text)\n",
    "                    triples.append(triple)\n",
    "                        \n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2pa(text):\n",
    "    nlp = etri.getETRI(text)    \n",
    "    conll_2009 = etri.getETRI_CoNLL2009(nlp)\n",
    "    predicate_argument = etri.phrase_parser(conll_2009, nlp)\n",
    "    return predicate_argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_identifier(conll):\n",
    "    text = ' '.join(conll[0][0])\n",
    "    pas = sent2pa(text)\n",
    "    \n",
    "    result = []\n",
    "    for anno in conll:\n",
    "        args = ['O' for i in range(len(anno[1]))]\n",
    "        for idx in range(len(anno[1])):\n",
    "            if anno[1][idx] != '_':\n",
    "                lu = anno[1][idx]\n",
    "                frame = anno[2][idx]\n",
    "                target_idx = idx\n",
    "        for pa in pas:\n",
    "            if target_idx == pa['predicate']['id']:\n",
    "                for argument in pa['arguments']:\n",
    "                    for idx in range(len(argument['tokens'])):\n",
    "                        token_id = argument['tokens'][idx]\n",
    "                        if idx == 0:\n",
    "                            bio = 'B-'\n",
    "                        else:\n",
    "                            bio = 'I-'\n",
    "                        fe = 'ARG'\n",
    "                        args[token_id] = bio+fe\n",
    "        new_anno = anno\n",
    "        new_anno.append(args)\n",
    "        result.append(new_anno)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data, sentence_id):\n",
    "    input_data = dataio.preprocessor(data)\n",
    "    text = data\n",
    "    tgt_data = targetid.baseline(input_data)\n",
    "    fid_data, fid_result  = fn_models.frame_identifier(tgt_data)    \n",
    "    argid_data = arg_identifier(fid_data)    \n",
    "    \n",
    "    framegraph = result2triples(text, argid_data, fid_result, sentence_id)\n",
    "    textae = conll2textae.get_textae(argid_data)\n",
    "        \n",
    "    result = {}\n",
    "    result['graph'] = framegraph\n",
    "    result['textae'] = textae\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('test:offset_0_53',\n",
      "  'nif:isString',\n",
      "  '헤밍웨이는 1899년 7월 21일 미국 일리노이에서 태어났고, 1961년 7월 2일 아이다호 주에서 사망했다.'),\n",
      " ('frame:Origin', 'frdf:provinence', 'test:offset_0_53'),\n",
      " ('frame:Origin', 'frdf:lu', '미국.n'),\n",
      " ('frame:Origin', 'frdf:score', '1.0'),\n",
      " ('frame:Being_born', 'frdf:provinence', 'test:offset_0_53'),\n",
      " ('frame:Being_born', 'frdf:lu', '태어나다.v'),\n",
      " ('frame:Being_born', 'frdf:score', '1.0'),\n",
      " ('frame:Being_born', 'frdf:arg', '헤밍웨이는'),\n",
      " ('frame:Being_born', 'frdf:arg', '1899년 7월 21일'),\n",
      " ('frame:Being_born', 'frdf:arg', '미국 일리노이에서'),\n",
      " ('frame:Political_locales', 'frdf:provinence', 'test:offset_0_53'),\n",
      " ('frame:Political_locales', 'frdf:lu', '주.n'),\n",
      " ('frame:Political_locales', 'frdf:score', '0.9832083582878113'),\n",
      " ('frame:Death', 'frdf:provinence', 'test:offset_0_53'),\n",
      " ('frame:Death', 'frdf:lu', '사망.n'),\n",
      " ('frame:Death', 'frdf:score', '1.0'),\n",
      " ('frame:Death', 'frdf:arg', '헤밍웨이는'),\n",
      " ('frame:Death', 'frdf:arg', '1961년 7월 2일'),\n",
      " ('frame:Death', 'frdf:arg', '아이다호 주에서')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "text = '헤밍웨이는 1899년 7월 21일 미국 일리노이에서 태어났고, 1961년 7월 2일 아이다호 주에서 사망했다.'\n",
    "stringuri = 'test:offset_0_53'\n",
    "parsed = main(text, stringuri)\n",
    "pprint(parsed['graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('test_0_0', 'nif:isString', '어니스트 헤밍웨이는 미국의 소설가이자 저널리스트이다.'),\n",
      " ('frame:Origin', 'frdf:provinence', 'test_0_0'),\n",
      " ('frame:Origin', 'frdf:lu', '미국.n'),\n",
      " ('frame:Origin', 'frdf:score', '1.0')]\n",
      "\n",
      "[('test_0_1', 'nif:isString', '1854년 노벨 문학상을 수상하였다.'),\n",
      " ('frame:Leadership', 'frdf:provinence', 'test_0_1'),\n",
      " ('frame:Leadership', 'frdf:lu', '수상.n'),\n",
      " ('frame:Leadership', 'frdf:score', '1.0'),\n",
      " ('frame:Leadership', 'frdf:arg', '1854년'),\n",
      " ('frame:Leadership', 'frdf:arg', '노벨 문학상을')]\n",
      "\n",
      "[('test_0_2', 'nif:isString', '헤밍웨이는 1899년 7월 21일 일리노이주에서 태어났다.'),\n",
      " ('frame:Being_born', 'frdf:provinence', 'test_0_2'),\n",
      " ('frame:Being_born', 'frdf:lu', '태어나다.v'),\n",
      " ('frame:Being_born', 'frdf:score', '1.0'),\n",
      " ('frame:Being_born', 'frdf:arg', '헤밍웨이는'),\n",
      " ('frame:Being_born', 'frdf:arg', '1899년 7월 21일'),\n",
      " ('frame:Being_born', 'frdf:arg', '일리노이주에서')]\n",
      "\n",
      "[('test_0_3', 'nif:isString', '헤밍웨이는 풀린 파이퍼와 이혼한 뒤 마사 겔혼과 재혼하였다.'),\n",
      " ('frame:Change_of_phase', 'frdf:provinence', 'test_0_3'),\n",
      " ('frame:Change_of_phase', 'frdf:lu', '풀리다.v'),\n",
      " ('frame:Change_of_phase', 'frdf:score', '1.0'),\n",
      " ('frame:Change_of_phase', 'frdf:arg', '이혼한'),\n",
      " ('frame:Forming_relationships', 'frdf:provinence', 'test_0_3'),\n",
      " ('frame:Forming_relationships', 'frdf:lu', '이혼.n'),\n",
      " ('frame:Forming_relationships', 'frdf:score', '1.0'),\n",
      " ('frame:Forming_relationships', 'frdf:arg', '풀린 파이퍼와'),\n",
      " ('frame:Forming_relationships', 'frdf:arg', '뒤'),\n",
      " ('frame:Part_orientational', 'frdf:provinence', 'test_0_3'),\n",
      " ('frame:Part_orientational', 'frdf:lu', '뒤.n'),\n",
      " ('frame:Part_orientational', 'frdf:score', '1.0')]\n",
      "\n",
      "[('test_0_4', 'nif:isString', '헤밍웨이는 1961년 아이다호 주에서 62세의 나이에 자살했다..'),\n",
      " ('frame:Political_locales', 'frdf:provinence', 'test_0_4'),\n",
      " ('frame:Political_locales', 'frdf:lu', '주.n'),\n",
      " ('frame:Political_locales', 'frdf:score', '0.9969702959060669'),\n",
      " ('frame:Calendric_unit', 'frdf:provinence', 'test_0_4'),\n",
      " ('frame:Calendric_unit', 'frdf:lu', '나이.n'),\n",
      " ('frame:Calendric_unit', 'frdf:score', '1.0'),\n",
      " ('frame:Killing', 'frdf:provinence', 'test_0_4'),\n",
      " ('frame:Killing', 'frdf:lu', '자살.n'),\n",
      " ('frame:Killing', 'frdf:score', '1.0'),\n",
      " ('frame:Killing', 'frdf:arg', '헤밍웨이는'),\n",
      " ('frame:Killing', 'frdf:arg', '1961년'),\n",
      " ('frame:Killing', 'frdf:arg', '아이다호 주에서'),\n",
      " ('frame:Killing', 'frdf:arg', '62세의 나이에')]\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "text = '어니스트 헤밍웨이는 미국의 소설가이자 저널리스트이다. 1854년 노벨 문학상을 수상하였다. 헤밍웨이는 1899년 7월 21일 일리노이주에서 태어났다. 헤밍웨이는 풀린 파이퍼와 이혼한 뒤 마사 겔혼과 재혼하였다. 헤밍웨이는 1961년 아이다호 주에서 62세의 나이에 자살했다.'\n",
    "sents = doc2sents(text)\n",
    "framegraphs = []\n",
    "for text, stringuri in sents:\n",
    "    parsed = main(text, stringuri)\n",
    "    pprint(parsed['graph'])\n",
    "    print('')\n",
    "#     framegraphs+=(parsed['framegraph'])\n",
    "pprint(framegraphs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
